{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSDL7013 Natural Language Processing Lab 6\n",
        "\n",
        "* NOTE: Prepend your Roll Number to the name of this file\n",
        "\n",
        "* YET ANOTHER NOTE: Take print out of the relevant code cells only."
      ],
      "metadata": {
        "id": "vKeGVu2k8Hmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part of Speech Tagging Lab\n",
        "\n",
        "1. **Title:**  Part of Speech Tagging\n",
        "\n",
        "2. **Objective/Aim:** \n",
        "\n",
        "**Part 1 :** To  implement viterbi algorithm for HMM\n",
        "\n",
        "**Part 2 :** To  illustrate parts of speech tagging and exploring tagged corpora using nltk and supporting libraries\n",
        "\n",
        "3. **Due Date:** Friday September 16, 2022\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5xL99s7p8OK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Name : \n",
        "\n",
        "### Roll Number :"
      ],
      "metadata": {
        "id": "u4CzHC3T82GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "1Id1JS-LR910"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_7sOgME4rvX"
      },
      "source": [
        "# Part of Speech Tagging Using Hidden Markov Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjzg9yf_3C5r"
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('brown')\n",
        "#nltk.download('universal_tagset')\n",
        "#nltk.download('tagsets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEJQx3WO3ms4"
      },
      "source": [
        "#text = \"I closed the last bag\"\n",
        "#ttoks = nltk.word_tokenize(text)\n",
        "#ttags = nltk.pos_tag(ttoks,tagset='universal')\n",
        "#ttags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGL6j0yf3_fv"
      },
      "source": [
        "# from nltk.corpus import brown\n",
        "\n",
        "# toi = ['DET','PRON','VERB','ADJ','NOUN'] # Tags_of_interest\n",
        "\n",
        "# trans = {} #Transition probabilities:  Matrix A\n",
        "\n",
        "# observation = \"I closed the last bag\" # Observation Sentence\n",
        "\n",
        "# owords = observation.split()\n",
        "\n",
        "# emission = {} # Emission probabilities: Matrix B\n",
        "\n",
        "\n",
        "# brown_mystery_tagged = brown.tagged_words(categories='mystery', tagset='universal')\n",
        "\n",
        "# tag_fd = nltk.FreqDist(tag for (word, tag) in brown_mystery_tagged)\n",
        "# w_tag_pairs = list(nltk.bigrams(brown_mystery_tagged))\n",
        "\n",
        "# for ti in toi:\n",
        "#   tag2 = [a[1] for (a, b) in w_tag_pairs if b[1] == ti]\n",
        "#   tag2_fd = nltk.FreqDist(tag2)\n",
        "#   starters = [b[1] for (a, b) in w_tag_pairs if a[0] == '.']\n",
        "#   starters_fd = nltk.FreqDist(starters)\n",
        "#   trans[('START',ti)] = starters_fd[ti] / tag_fd[ti] \n",
        "#   for tj in toi:\n",
        "#     trans[(ti,tj)] = tag2_fd[tj] / tag_fd[ti] # matrix A\n",
        "#   for word in owords:\n",
        "#     wordcnt = len([t for (w,t) in brown_mystery_tagged if w == word and t == ti])\n",
        "#     emission[(ti,word)] = wordcnt / tag_fd[ti] # matrix B\n",
        "\n",
        "# for t,p in trans.items():\n",
        "#   print(t,\" : \",p)\n",
        "\n",
        "# for e,p in emission.items():\n",
        "#   print(e,\" : \",p)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ira6MkMB5Jsu"
      },
      "source": [
        "### Implement your viterbi algorithm\n",
        "\n",
        "[*05 Marks*]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Your Viterbi Algorithm"
      ],
      "metadata": {
        "id": "4um7lCBrN-11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "bIzLDDcXSBPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1\n",
        "Get acquainted with various tags in different corpus.  Write explanation about two tags from each corpora.\n",
        "        Check other tags, namely, JJ, RB, VB etc. How do you list all tags in a corpora?"
      ],
      "metadata": {
        "id": "jTcksDJqQAYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('tagsets')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('brown')\n",
        "#nltk.download('universal_tagset')\n",
        "#nltk.download('nps_chat')\n",
        "#nltk.download('treebank')"
      ],
      "metadata": {
        "id": "rnwl6zKpQJNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nltk.help.upenn_tagset('NN')"
      ],
      "metadata": {
        "id": "42yFj2bIQP4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try out various labels for tagsets in place of 'NN' in the above code snippet.  Like 'VB', 'JJ',... \n",
        "\n",
        "### You can also use regular expressions...\n",
        "\n",
        "NN*     -->     Everything starting with NN\n",
        "\n",
        "JJ*     -->     Everything starting with JJ\n",
        "\n",
        ".*      -->     All tagsets\n",
        "\n",
        "\n",
        "### Check other tagsets also.\n",
        "\n",
        "In a new code cell, try out\n",
        "\n",
        "nltk.help.claws5_tagset(\"NN*\")\n",
        "\n",
        "nltk.help.brown_tagset(\"JJ*\")\n"
      ],
      "metadata": {
        "id": "1C1llq7DQUtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2\n",
        "Read the file. Tokenize and tag each word."
      ],
      "metadata": {
        "id": "BqQlFIZrQh5o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mrxBhJiPqGS"
      },
      "outputs": [],
      "source": [
        "# NOTE: You need to upload file, say in tmp folder.\n",
        "\n",
        "#f = open('tmp/hitchhikersguidetogalaxy.txt')\n",
        "#txt = f.read()\n",
        "#tokens = nltk.word_tokenize(txt)\n",
        "#nltk.pos_tag(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q 3\n",
        "Write code to find most frequent\n",
        "\n",
        "\n",
        "*   Noun Tags\n",
        "*   Adjective tags\n",
        "* Verb tags\n",
        "* Adverb tags\n"
      ],
      "metadata": {
        "id": "CiloNlRgRLPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def findtags(tag_prefix, tagged_text):\n",
        "#    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
        "#                                  if tag.startswith(tag_prefix))\n",
        "#    return dict((tag, cfd[tag].most_common(5)) for tag in cfd.conditions())"
      ],
      "metadata": {
        "id": "3daGnAxhRlT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: change NN to whatever tag that you want\n",
        "\n",
        "#tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='mystery'))\n",
        "#for tag in sorted(tagdict):\n",
        "#  print(tag, tagdict[tag])"
      ],
      "metadata": {
        "id": "wBpmgFyMRpqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q 4\n",
        "\n",
        "Find  the next word of a given word.\n",
        "\n",
        "Find part of speech tag of the next word of a given word. "
      ],
      "metadata": {
        "id": "QXBosVCYR6AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 4. (a)\n",
        "# NOTE: change category and word for different results\n",
        "# category = mystery, learned, ...\n",
        "# Uncomment lines below\n",
        "\n",
        "#from nltk.corpus import brown\n",
        "\n",
        "#category = \"news\"\n",
        "#word = \"what\"\n",
        "\n",
        "#mytext = brown.words(categories=category)\n",
        "#sorted(set(b for (a, b) in nltk.bigrams(mytext) if a == word))"
      ],
      "metadata": {
        "id": "hJoSMmRiSHfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q 4. (b)\n",
        "# NOTE: change category and word for different results\n",
        "# category = mystery, learned, ...\n",
        "# Uncomment lines below\n",
        "\n",
        "#from nltk.corpus import brown\n",
        "\n",
        "#category = \"news\"\n",
        "#word = \"what\"\n",
        "\n",
        "\n",
        "#mytags = brown.tagged_words(categories=category, tagset='universal')\n",
        "#tags = [b[1] for (a, b) in nltk.bigrams(mytags) if a[0] == word]\n",
        "#fd = nltk.FreqDist(tags)\n",
        "#fd.tabulate()"
      ],
      "metadata": {
        "id": "KiJku41LTY6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q 5\n",
        "\n",
        " Perform Unigram Tagging"
      ],
      "metadata": {
        "id": "zQtCpne9V2PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from nltk.corpus import brown\n",
        "\n",
        "#category = \"mystery\"\n",
        "#word_index = 1976\n",
        "\n",
        "#my_tagged_sents_for_training = brown.tagged_sents(categories=category)\n",
        "#my_sents_for_testing = brown.sents(categories=category)\n",
        "#my_unigram_tagger = nltk.UnigramTagger(my_tagged_sents_for_training)\n",
        "#my_unigram_tagger.tag(my_sents_for_testing[word_index])\n"
      ],
      "metadata": {
        "id": "09llyAElVvrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my_unigram_tagger.evaluate(my_tagged_sents_for_training)"
      ],
      "metadata": {
        "id": "ku-Q6yWsV0Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your Wild Imagination\n",
        "\n",
        "[*05 Marks*]"
      ],
      "metadata": {
        "id": "68hpBOFsT_Qj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTtOxwjPRHlV"
      },
      "outputs": [],
      "source": [
        "# Scratch Pad... Do something wonderful over here... Of course, relevant to this lab."
      ]
    }
  ]
}